{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOBb8tkvvxGJX0is3H0Aqkl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boyerb/Investments/blob/master/Exxx-Performance_Attribution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Investment Analysis**, Bates, Boyer, Fletcher"
      ],
      "metadata": {
        "id": "v1-FRCWfNNzj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example Chapter xx: Contributions to Alpha Using Time Series Regressions\n",
        "In this example we estimate allocation and selection effects for alpha."
      ],
      "metadata": {
        "id": "wl_z3z0XNdKE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports and Setup"
      ],
      "metadata": {
        "id": "3UNyIApsTXA3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LLQnh4XkNMG4"
      },
      "outputs": [],
      "source": [
        "#import packages\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load in Data\n",
        "We load stock returns, benchmark weights, and portfolio weights from the spreadsheet. In this file, the column labels (`A`, `B`, `C`,...) are repeated for each block of data in row 2 . When Python encounters duplicate column names while reading the spreadsheet, it automatically appends suffixes `.1`, `.2`, `.3`, and so on to distinguish them.    "
      ],
      "metadata": {
        "id": "J6TjOu6pTOJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in the data by first specifying the URL where the data can be found\n",
        "url='https://github.com/boyerb/Investments/raw/master/Examples_3.46.xlsx'\n",
        "# specify which columns to read\n",
        "columns_to_read = ['Date', 'A','B','C','D','E','A.1','B.1','C.1','D.1','E.1','A.2','B.2','C.2','D.2','E.2']\n",
        "df = pd.read_excel(url, sheet_name='PA-2', header=1, usecols=columns_to_read, engine='openpyxl')\n",
        "df = df.dropna()\n",
        "\n",
        "# Split into the three panels and set the Date columns as the index\n",
        "stock_returns = df[['Date','A','B','C','D','E']].set_index('Date')\n",
        "\n",
        "benchmark_weights = df[['Date','A.1','B.1','C.1','D.1','E.1']].copy()\n",
        "benchmark_weights.columns = ['Date','A','B','C','D','E']\n",
        "benchmark_weights = benchmark_weights.set_index('Date')\n",
        "\n",
        "portfolio_weights = df[['Date','A.2','B.2','C.2','D.2','E.2']].copy()\n",
        "portfolio_weights.columns = ['Date','A','B','C','D','E']\n",
        "portfolio_weights = portfolio_weights.set_index('Date')"
      ],
      "metadata": {
        "id": "1tiW8x2OTKv7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate Returns for Every Period\n",
        "We calculate the benchmark return, portfolio return, and excess returns each period. We are given that the risk-free rate is 25 basis points per month."
      ],
      "metadata": {
        "id": "guaEg_GIUzjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "benchmark_return = (stock_returns  * benchmark_weights).sum(axis=1)\n",
        "portfolio_return = (stock_returns  * portfolio_weights).sum(axis=1)\n",
        "benchmark_excess_return = benchmark_return - 0.0025\n",
        "portfolio_excess_return = portfolio_return - 0.0025"
      ],
      "metadata": {
        "id": "TkZGC1HsbEzc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate Portfolio and Benchmark Segment Weights\n",
        "We next group securities into two segments:\n",
        "\n",
        "* Segment 1 (Seg1): the first three securities (A, B, C)\n",
        "* Segment 2 (Seg2): the last two securities (D, E)\n",
        "\n",
        "For each date, we sum the portfolio weights and benchmark weights within these groups to obtain segment-level weights. The key part of the code is the use of sum(axis=1), which tells pandas to sum across columns (horizontally) for each row. Since each row represents a date, this produces the total weight for that segment on that date."
      ],
      "metadata": {
        "id": "BBoWbdvLVWdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "portfolio_segment_weights = pd.DataFrame({\n",
        "    'Seg1': portfolio_weights.iloc[:, 0:3].sum(axis=1),  # sum of first 3 columns\n",
        "    'Seg2': portfolio_weights.iloc[:, 3:5].sum(axis=1)   # sum of last 2 columns\n",
        "}, index=portfolio_weights.index)\n",
        "\n",
        "benchmark_segment_weights = pd.DataFrame({\n",
        "    'Seg1': benchmark_weights.iloc[:, 0:3].sum(axis=1),  # sum of first 3 columns\n",
        "    'Seg2': benchmark_weights.iloc[:, 3:5].sum(axis=1)   # sum of last 2 columns\n",
        "}, index=benchmark_weights.index)"
      ],
      "metadata": {
        "id": "AokWWTxPbaUo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate Security Segment Weights\n",
        "Now we normalize each security’s weight within its segment so that the weights inside a segment always sum to 1. This is done separately for the portfolio and the benchmark.  \n",
        "Step 1. Select columns with .iloc\n",
        " * Code snippet: `portfolio_weights.iloc[:, 0:3]`\n",
        " * The colon, `:`, means \"select all rows\" (i.e., every date).\n",
        " * The second part 0:3 means “select columns 0 through 2” (Python indexing is zero-based and stops before 3).  \n",
        " * So this picks out securities A, B, C from the portfolio weights DataFrame.\n",
        "\n",
        "Step 2. Divide row by row\n",
        " * Code snippet: `.div(portfolio_segment_weights['Seg1'], axis=0)`  \n",
        " * axis=0 means match by row index (i.e., by date).\n",
        " * Each security’s weight for a given date is divided by the total segment weight for that same date.\n",
        " * This ensures that inside each segment, the security-segment weights sum to 1 per date.\n",
        "\n",
        "Step 3. Concatenate side by side\n",
        " * Code snippet: `pd.concat([pssw1, pssw2], axis=1)`\n",
        " * `axis=1` means combine along columns (side by side).\n",
        " * Here, the two DataFrames (pssw1 for A–C, pssw2 for D–E) are joined into one DataFrame with all five securities.\n"
      ],
      "metadata": {
        "id": "9YlxLvEbXvGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcaute Portfolio Security Segment Weights (pssw)\n",
        "pssw1 = portfolio_weights.iloc[:, 0:3].div(portfolio_segment_weights['Seg1'], axis=0)\n",
        "pssw2 = portfolio_weights.iloc[:, 3:5].div(portfolio_segment_weights['Seg2'], axis=0)\n",
        "portfolio_security_segment_weights = pd.concat([pssw1, pssw2], axis=1)\n",
        "\n",
        "# Calculate Benchmark Security Segment Weights (bssw)\n",
        "bssw1 = benchmark_weights.iloc[:, 0:3].div(benchmark_segment_weights['Seg1'], axis=0)\n",
        "bssw2 = benchmark_weights.iloc[:, 3:5].div(benchmark_segment_weights['Seg2'], axis=0)\n",
        "benchmark_security_segment_weights = pd.concat([bssw1, bssw2], axis=1)"
      ],
      "metadata": {
        "id": "LEnpvwkYdaGr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate Segment Returns\n",
        "Now we want the return for each segment of the portfolio and the benchmark.\n",
        "\n",
        " * Segment 1 = A, B, C\n",
        " * Segment 2 = D, E\n",
        "\n",
        "Because we already normalized the security-segment weights so they sum to 1 within each segment, we can calculate a segment's return as the weighted average of its securities' returns.  \n",
        " * `.iloc[:, :3]` :  select all rows (:) and the first three columns (0,1,2), which correspond to A, B, C.\n",
        " * `.iloc[:, 3:5]` :  select all rows and the last two columns (3,4), which correspond to D, E.\n",
        " * `.sum(axis=1)` means sum across the columns for each row (date), giving the segment's return on that date.  \n",
        "\n",
        "After we calculate the return for each segment (port_seg1_ret and port_seg2_ret), we want to store them together in one table (a pandas DataFrame) so it's easy to use later.\n",
        " * `pd.DataFrame({...})` creates a new DataFrame.\n",
        " * Inside the curly braces `{}`, we pass in a dictionary:\n",
        "  * The key (e.g., `'Port_Seg1_Return'`) becomes the column name.\n",
        "  * The value (e.g., `port_seg1_ret`) is the data for that column.\n",
        "  * `index=stock_returns.index` tells pandas to use the same row labels (dates) as the original stock returns DataFrame. This way, each segment return lines up correctly with the same dates as the stock data."
      ],
      "metadata": {
        "id": "Uu4WyJeP0Kt3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Portfolio segment returns (weights within each segment sum to 1)\n",
        "port_seg1_ret = (portfolio_security_segment_weights.iloc[:, :3] * stock_returns.iloc[:, :3]).sum(axis=1)\n",
        "port_seg2_ret = (portfolio_security_segment_weights.iloc[:, 3:5] * stock_returns.iloc[:, 3:5]).sum(axis=1)\n",
        "\n",
        "portfolio_segment_returns = pd.DataFrame(\n",
        "    {'Port_Seg1_Return': port_seg1_ret, 'Port_Seg2_Return': port_seg2_ret},\n",
        "    index=stock_returns.index\n",
        ")\n",
        "\n",
        "# Benchmark segment returns\n",
        "bench_seg1_ret = (benchmark_security_segment_weights.iloc[:, :3] * stock_returns.iloc[:, :3]).sum(axis=1)\n",
        "bench_seg2_ret = (benchmark_security_segment_weights.iloc[:, 3:5] * stock_returns.iloc[:, 3:5]).sum(axis=1)\n",
        "\n",
        "benchmark_segment_returns = pd.DataFrame(\n",
        "    {'Bench_Seg1_Return': bench_seg1_ret, 'Bench_Seg2_Return': bench_seg2_ret},\n",
        "    index=stock_returns.index\n",
        ")"
      ],
      "metadata": {
        "id": "8ZnRQeWofJ_0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate Allocation Effects\n",
        "The allocation effect measures how much of the portfolio's performance relative to the benchmark comes from over- or under-weighting segments, compared to the benchmark.\n",
        "\n",
        "For each segment:\n",
        " * Take the difference in weights (portfolio weight - benchmark weight).\n",
        " * Multiply by the difference between the benchmark's return for that segment and the overall benchmark return.\n",
        "\n",
        "This tells us whether putting more (or less) weight into a segment helped or hurt performance.\n",
        "\n",
        " * `portfolio_segment_weights['Seg1']` - benchmark_segment_weights['Seg1']` : $(W_{p,1}-W_{b,1})$, the difference in segment weights.\n",
        " * `benchmark_segment_returns['Bench_Seg1_Return'] - benchmark_return` : $(r_{b,1}-r_b)$, the difference in returns\n",
        "\n",
        "We then collect the allocation effects into a dataframe, using code similar to that in the previous block, with three columns: (1) allocation to segment 1, (2) allocation to segment 2, and (3) the total allocation effect.  The index of the dataframe is the row date.  "
      ],
      "metadata": {
        "id": "6XKozXnb2cHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alloc_seg1 = (portfolio_segment_weights['Seg1'] - benchmark_segment_weights['Seg1']) * \\\n",
        "             (benchmark_segment_returns['Bench_Seg1_Return'] - benchmark_return)\n",
        "\n",
        "alloc_seg2 = (portfolio_segment_weights['Seg2'] - benchmark_segment_weights['Seg2']) * \\\n",
        "             (benchmark_segment_returns['Bench_Seg2_Return'] - benchmark_return)\n",
        "\n",
        "allocation = pd.DataFrame(\n",
        "    {\n",
        "        'Allocation_Seg1': alloc_seg1,\n",
        "        'Allocation_Seg2': alloc_seg2,\n",
        "        # optional total:\n",
        "        'Allocation_Total': alloc_seg1 + alloc_seg2\n",
        "    },\n",
        "    index=benchmark_return.index  # same as your dates\n",
        ")"
      ],
      "metadata": {
        "id": "kt7vBRx4hS2K"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate Selection Effects\n",
        "The selection effect measures how much of the portfolio's performance relative to the benchmark comes from over- or under-weighting specific securities within each segment. Here we include the interaction term with the selection effect.\n",
        "\n",
        "For each segment:\n",
        " * Multiply by the portfolio segment weight by the difference between the portfolio's return for that segment and the benchmark's return for that segment.\n",
        "\n",
        " * `portfolio_segment_weights['Seg1']`: $W_{p,1}$, the portfolio segment weight.\n",
        " * `portfolio_segment_returns['Port_Seg1_Return'] - benchmark_segment_returns['Bench_Seg1_Return']` : $(r_{p,1}-r_{b,1})$, the difference in segment returns\n",
        "\n",
        "We then collect the selection effects into a dataframe, using code similar to that in the previous block, with three columns: (1) selection within segment 1, (2) selection within segment 2, and (3) the total selection effect.  The index of the dataframe is the row date.  "
      ],
      "metadata": {
        "id": "fqgmDLL04m9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selection effect for Segment 1\n",
        "sel_seg1 = portfolio_segment_weights['Seg1'] * (\n",
        "    portfolio_segment_returns['Port_Seg1_Return'] - benchmark_segment_returns['Bench_Seg1_Return']\n",
        ")\n",
        "\n",
        "# Selection effect for Segment 2\n",
        "sel_seg2 = portfolio_segment_weights['Seg2'] * (\n",
        "    portfolio_segment_returns['Port_Seg2_Return'] - benchmark_segment_returns['Bench_Seg2_Return']\n",
        ")\n",
        "\n",
        "# Combine into one DataFrame\n",
        "selection = pd.DataFrame(\n",
        "    {\n",
        "        'Selection_Seg1': sel_seg1,\n",
        "        'Selection_Seg2': sel_seg2,\n",
        "        # optional: total\n",
        "        'Selection_Total': sel_seg1 + sel_seg2\n",
        "    },\n",
        "    index=portfolio_segment_weights.index\n",
        ")"
      ],
      "metadata": {
        "id": "Nq7vWYKiiUJB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calcculate Average Effects\n",
        "Here we caculate average allocation and selection effects, and collect results into a dataframe."
      ],
      "metadata": {
        "id": "vKcBiNLc5p9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg_effects = {\n",
        "    'Allocation_Seg1': allocation['Allocation_Seg1'].mean(),\n",
        "    'Allocation_Seg2': allocation['Allocation_Seg2'].mean(),\n",
        "    'Selection_Seg1':  selection['Selection_Seg1'].mean(),\n",
        "    'Selection_Seg2':  selection['Selection_Seg2'].mean(),\n",
        "}\n",
        "\n",
        "# Build DataFrame\n",
        "avg_df = pd.DataFrame.from_dict(avg_effects, orient='index', columns=['Average_Effect'])\n",
        "\n",
        "# Add total row\n",
        "avg_df.loc['Total'] = avg_df['Average_Effect'].sum()"
      ],
      "metadata": {
        "id": "baPcA7b8mFzp"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculate Portfolio Alpha"
      ],
      "metadata": {
        "id": "Go9KJv6i5_CS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X = benchmark excess return, Y = portfolio excess return\n",
        "X = sm.add_constant(benchmark_excess_return)  # adds intercept (alpha)\n",
        "y = portfolio_excess_return\n",
        "\n",
        "model = sm.OLS(y, X).fit()\n",
        "portfolio_alpha = model.params['const']\n",
        "print(\"Portfolio alpha:\", portfolio_alpha)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30iTdSaRjzLC",
        "outputId": "1c204ec6-1afd-4b69-e68c-901b25f22092"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Portfolio alpha: 0.0022732518211335197\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Estimating Component Alphas\n",
        "\n",
        "Now we want to see how much each effect (allocation or selection) contributes to the portfolio’s overall alpha.\n",
        "\n",
        "The idea: for each component time series, we run a regression of the component’s return on the benchmark’s excess return. The intercept of this regression is the component alpha.\n",
        "\n",
        " * The `for` loop goes through each column name (two allocation effects and two selection effects).\n",
        " * `y_piece` is the data for that component.\n",
        " * `sm.add_constant(...)` adds a column of 1s so the regression can estimate an intercept (the alpha).\n",
        " * `sm.OLS(y_piece, X).fit()` runs an Ordinary Least Squares regression.\n",
        " * `model.params['const']` extracts the intercept, which is the component's alpha.\n",
        " * `pd.DataFrame.from_dict(...)` turns the dictionary of alphas into a nice table.\n",
        " * `alpha_df.loc['Total']` adds up all the alphas to show that the sum equals the portfolio alpha."
      ],
      "metadata": {
        "id": "rN4oObcz6Cxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alphas = {}\n",
        "\n",
        "for col in ['Allocation_Seg1','Allocation_Seg2',\n",
        "            'Selection_Seg1','Selection_Seg2']:\n",
        "    y_piece = allocation[col] if 'Allocation' in col else selection[col]\n",
        "    X = sm.add_constant(benchmark_excess_return)\n",
        "    model = sm.OLS(y_piece, X).fit()\n",
        "    alphas[col] = model.params['const']\n",
        "\n",
        "# Convert to DataFrame\n",
        "alpha_df = pd.DataFrame.from_dict(alphas, orient='index', columns=['Alpha'])\n",
        "alpha_df.loc['Total'] = alpha_df['Alpha'].sum()"
      ],
      "metadata": {
        "id": "8FvXJuIWki5m"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Alpha Check\n",
        "Check to verify that the portfolio alpha is the sum of the component alphas."
      ],
      "metadata": {
        "id": "P9GBEmby651t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Portfolio alpha:\", portfolio_alpha)\n",
        "print(\"Sum of attribution alphas:\", alpha_df.loc['Total','Alpha'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EK3rKS3Lkphp",
        "outputId": "41a4bb04-8e60-4357-bf4c-10526c7a6154"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Portfolio alpha: 0.0022732518211335197\n",
            "Sum of attribution alphas: 0.0022732518211335223\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Annualize, Merge and Display Results\n",
        "Here we combine the total attrribution and alpha attribution effects, and display the results."
      ],
      "metadata": {
        "id": "uBosYAvC7HiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiply each DataFrame by 12 to Annualize\n",
        "avg_df_annualized = avg_df * 12\n",
        "alpha_df_annualized = alpha_df * 12\n",
        "\n",
        "# Combine side by side\n",
        "combined = pd.concat([avg_df_annualized, alpha_df_annualized], axis=1)\n",
        "\n",
        "print(combined)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkOzF88omUvt",
        "outputId": "c67ceb74-0446-4dd0-d5f8-88511efd68cc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 Average_Effect     Alpha\n",
            "Allocation_Seg1        0.000608  0.000351\n",
            "Allocation_Seg2        0.002328  0.001340\n",
            "Selection_Seg1         0.038616  0.027764\n",
            "Selection_Seg2         0.005234 -0.002176\n",
            "Total                  0.046786  0.027279\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summary\n",
        "Selection to Segment 1 seems to be the driving force of both the total performance spread and alpha."
      ],
      "metadata": {
        "id": "sVEnG-Cm70OE"
      }
    }
  ]
}